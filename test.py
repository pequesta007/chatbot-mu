import fitz  # PyMuPDF
import json
import ftfy
import unicodedata
import re
import os

UPLOAD_FOLDER = "uploads"
DATA_FILE = "data.json"

# üîπ Diccionario extendido para corregir palabras fragmentadas y caracteres mal extra√≠dos
reemplazos = {
    "Ô¨Å": "fi", "Ô¨Ç": "fl", "Ô¨É": "ffi", "Ô¨Ñ": "ffl", "Ô¨Ö": "ft", "Ô¨Ü": "st",
    "Ô¨Ä": "ff", "\ufb01": "fi", "\ufb02": "fl", "\ufb05": "ft",
    "G es √≥n": "Gesti√≥n", "G es√≥n": "Gesti√≥n", "G e s t i √≥ n": "Gesti√≥n",
    "iden/dad": "identidad", "tes/gos": "testigos", "alimenta/ci√≥n": "alimentaci√≥n",
    "aten/ci√≥n": "atenci√≥n", "reac/ci√≥n": "reacci√≥n", "incen/var": "incentivar",
    "no/ficaciones": "notificaciones", "ges/on": "gesti√≥n", "reproducvo": "reproductivo",
    "plas/ficarlo": "plastificarlo", "comu/cate": "comun√≠cate", "mo/vo": "motivo",
    "concienzaci√≥n": "concienciaci√≥n", "po, fecha": "tipo, fecha",
    "vacunaci√≥n y esterilizaci√≥n gratuitas": "vacunaci√≥n y esterilizaci√≥n gratuitas",
    "educaci√≥n y concienzaci√≥n": "educaci√≥n y concienciaci√≥n",
    "interac/vos": "interactivos", "infograFas": "infograf√≠as", "expl/ca/vos": "explicativos",
    "Ges√≥n": "Gesti√≥n", "buenas pr√°ccas": "buenas pr√°cticas", "Tesgos": "Testigos",
    "idenficar": "identificar", "incenvar": "incentivar", "idendad": "identidad",
    "fotosvideos": "fotos y videos", "explicavos": "explicativos",
    "noficaciones": "notificaciones", "empo": "tiempo", "movo": "motivo",
    "diagn√≥sco": "diagn√≥stico", "rescastas": "rescatistas", "acva": "activa",
    "internexterna": "interna/externa", "machohembra": "macho/hembra",
    "esterilizadono": "esterilizado / no", "5sica": "f√≠sica", "candad": "cantidad",
    "diagnoscadas": "diagnosticadas", "acvidad": "actividad", "comparr": "compartir",
    "ancipaci√≥n": "anticipaci√≥n", "runa de paseos": "rutina de paseos",
    "Fsico": "F√≠sico", "ttiemporales": "temporales", "ttiemporal": "temporal",
    "interacvos": "interactivos", "desparasitaciones (internaexterna": "desparasitaciones (interna/externa",
    "rutina de paseos y acvidad f√≠sica": "rutina de paseos y actividad f√≠sica",
    "tenencia responsable, derechos de los animales y buenas pr√°ccas": "tenencia responsable, derechos de los animales y buenas pr√°cticas"
}

# üîπ Caracteres invisibles y s√≠mbolos no deseados
caracteres_a_eliminar = re.compile(r'[\x00-\x1F\x7F-\x9F‚òª‚òº‚ôÄ‚ôÇ‚ô´‚ñ∫‚Ä¢‚Üë/]')

# üîπ Extraer texto con mayor precisi√≥n
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    
    for page in doc:
        text += page.get_text("text") + "\n"
    
    return text.strip()

# üîπ Limpiar y corregir el texto extra√≠do
def clean_text(text):
    text = ftfy.fix_text(text)  # üîπ Corrige errores de codificaci√≥n
    text = unicodedata.normalize("NFKC", text)  # üîπ Normaliza caracteres Unicode
    text = caracteres_a_eliminar.sub('', text)  # üîπ Elimina caracteres invisibles
    
    # üîπ Corregir palabras fragmentadas con m√°s precisi√≥n
    for original, corregido in reemplazos.items():
        text = re.sub(re.escape(original), corregido, text, flags=re.IGNORECASE)
    
    return text.strip()

# üîπ Guardar en JSON sin perder la estructura
def save_to_json(data, json_path=DATA_FILE):
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print(f"‚úÖ Datos guardados en `{json_path}` correctamente.")

# üîπ Procesar TODOS los PDFs en `uploads/`
def process_all_pdfs(upload_folder=UPLOAD_FOLDER, json_path=DATA_FILE):
    data = {}
    if os.path.exists(json_path):
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except json.JSONDecodeError:
            data = {}
    
    for filename in os.listdir(upload_folder):
        if filename.lower().endswith(".pdf"):
            pdf_path = os.path.join(upload_folder, filename)
            print(f"üìÑ Procesando: {filename}")

            extracted_text = extract_text_from_pdf(pdf_path)
            cleaned_text = clean_text(extracted_text)
            
            # üîπ Guardar con estructura limpia
            data[filename] = cleaned_text
    
    save_to_json(data)

# üîπ Ejecutar extracci√≥n y guardar en JSON
if __name__ == "__main__":
    process_all_pdfs()
